# Radiology Agent QC: Intelligent Agents for Imaging Workflow Quality & Consistency

## ğŸ§© Problem Statement
Radiology teams need a reliable way to **monitor image quality, protocol adherence, metadata completeness, dose safety**, and **AI drift** across scanners, modalities, and sitesâ€”**without slowing down operations**. Manual spotâ€‘checks miss subtle issues and donâ€™t scale.

This repository provides a **reference implementation** of an **agentic system** that ingests imaging events and **automatically flags issues** with suggested fixes. Itâ€™s vendorâ€‘neutral and designed to sit alongside **RIS/EMR, PACS/VNA, DICOM MWL, and AI services**.

## ğŸ“¦ Whatâ€™s Inside
- **Agents** for Protocol, Image Quality, Dose, Metadata, Drift, and Governance
- A **streaming pipeline** (simulated) that turns events into findings
- **Quality checks** using rules + basic image metrics (noâ€‘reference surrogates)
- **Reproducible scripts**, tests, example data, and a clear stepâ€‘byâ€‘step guide
- Optional FastAPI service to expose findings and health

> Note: This repo includes **synthetic sample data**. Swap in your own DICOM directories to run against real studies.

---

## ğŸ—‚ï¸ Repository Structure
```
radiology-agent-qc/
â”œâ”€ src/
â”‚  â”œâ”€ agents/
â”‚  â”‚  â”œâ”€ protocol_agent.py
â”‚  â”‚  â”œâ”€ image_quality_agent.py
â”‚  â”‚  â”œâ”€ dose_agent.py
â”‚  â”‚  â”œâ”€ metadata_agent.py
â”‚  â”‚  â”œâ”€ drift_agent.py
â”‚  â”‚  â””â”€ governance_agent.py
â”‚  â”œâ”€ common/
â”‚  â”‚  â”œâ”€ models.py
â”‚  â”‚  â”œâ”€ dicom_utils.py
â”‚  â”‚  â”œâ”€ metrics.py
â”‚  â”‚  â””â”€ rules.py
â”‚  â””â”€ pipelines/
â”‚     â”œâ”€ ingest_simulator.py
â”‚     â””â”€ qc_pipeline.py
â”œâ”€ configs/
â”‚  â”œâ”€ rules.yaml
â”‚  â””â”€ paths.example.yaml
â”œâ”€ data/
â”‚  â””â”€ sample/
â”‚     â”œâ”€ metadata_sample.csv
â”‚     â””â”€ study_events.csv
â”œâ”€ notebooks/
â”‚  â””â”€ 01_explore_metrics.ipynb
â”œâ”€ tests/
â”‚  â”œâ”€ test_agents.py
â”‚  â””â”€ test_metrics.py
â”œâ”€ scripts/
â”‚  â”œâ”€ run_qc.sh
â”‚  â””â”€ demo_run.py
â”œâ”€ docker/
â”‚  â””â”€ Dockerfile
â”œâ”€ requirements.txt
â”œâ”€ LICENSE
â”œâ”€ .gitignore
â””â”€ README.md
```

---

## ğŸ§ª Datasets
- **Sample CSVs** (in `data/sample/`) emulate imaging events and minimal DICOM metadata.
- To run on **real DICOM**: point `paths.dicom_root` in `configs/paths.example.yaml` to your folder. The code uses `pydicom`/`SimpleITK` to read pixel data & headers.

### External references (background & metrics)
We draw on concepts similar to **MRQy** (openâ€‘source MRI QC for cohort variability and artifacts) for certain noâ€‘reference metrics and metadata checks. See the paper for details on measures like **CJV, PSNR, SNR variants, EFC, FBER**, etc. (Sadri et al., 2020).

---

## ğŸ› ï¸ Tools & Methods
- **Ruleâ€‘based checks**: simple, explainable policy violations (e.g., missing tags, laterality mismatch, protocol name offâ€‘catalog).
- **Noâ€‘reference metrics** (skimage/SimpleITK): noise proxies, entropy focus criterion, contrastâ€‘toâ€‘noise proxies.
- **Drift detection**: rolling zâ€‘scores/EWMA on repeat rates, protocol adherence, basic PSI proxy.
- **Great Expectations** for metadata completeness tests.
- **Agent orchestration** via a simple pipeline; optionally expose via **FastAPI**.

---

## â–¶ï¸ Quickstart (Stepâ€‘byâ€‘Step)

### 1) Create environment
```bash
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate
pip install -r requirements.txt
```

### 2) Configure paths
Copy and edit:
```bash
cp configs/paths.example.yaml configs/paths.yaml
```
Set `dicom_root` to your local DICOM directory (or leave blank to use sample CSV flows).

### 3) Run the demo pipeline
```bash
python scripts/demo_run.py --use-sample
```
This will:
- simulate ingest of study events,
- run all agents,
- write findings to `outputs/findings.csv` and a JSONL audit log.

### 4) (Optional) Run FastAPI service
```bash
uvicorn src.pipelines.qc_pipeline:app --reload
```
Endpoints:
- `GET /health`
- `GET /findings`
- `GET /stats`

### 5) Explore metrics
Open the notebook:
```
notebooks/01_explore_metrics.ipynb
```

---

## âœ… Results (sample run)
- Findings are emitted with: `severity`, `category`, `metric`, `actual`, `expected`, `explanation`, `study_uid`.
- Example: `protocol_adherence` â†’ â€œCT_ABD_WC expected slice_thickness 1â€“2.5mm; found 5.0mm; scanner=CT3; technologist=T42.â€
- Example: `image_quality` â†’ â€œHigh motion likelihood (EFC â†‘); consider repeat before patient leaves.â€

You can visualize weekly KPIs in the notebook (repeat rates, adherence, PSI proxy).

---

## ğŸ§­ Reproducibility
- **Fully scripted run** via `scripts/run_qc.sh` or `python scripts/demo_run.py`.
- Deterministic seeds where applicable.
- Clear separation between **config**, **code**, **data**, and **outputs**.

---

## ğŸ§° Extending
- Add siteâ€‘specific **rules** in `configs/rules.yaml`.
- Implement new metrics in `src/common/metrics.py`.
- Plug in real event sources (Kafka, Orthanc) by replacing `ingest_simulator.py`.

---

## ğŸ” Compliance Note
This reference implementation ships with **no PHI**. When using real data, ensure HIPAA controls (access, audit, deâ€‘ID).

---

## ğŸ“š Citation
If you use the MRI qualityâ€‘metric ideas, please cite the MRQy paper (Sadri et al., 2020).

---

## ğŸ“„ License
MIT (see LICENSE).

